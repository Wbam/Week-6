{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('C:/Users/bam/Downloads/Compressed/data-2024/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
      "       'CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId',\n",
      "       'ProductCategory', 'ChannelId', 'Amount', 'Value',\n",
      "       'TransactionStartTime', 'PricingStrategy', 'FraudResult'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aggregate features for each customer\n",
    "aggregate_features = data.groupby('CustomerId').agg(\n",
    "    total_transaction_amount=('Amount', 'sum'),\n",
    "    average_transaction_amount=('Amount', 'mean'),\n",
    "    transaction_count=('TransactionId', 'count'), \n",
    "    std_dev_transaction_amount=('Amount', 'std')  \n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'TransactionStartTime' to datetime\n",
    "data['TransactionStartTime'] = pd.to_datetime(data['TransactionStartTime'])\n",
    "\n",
    "# Extract features\n",
    "data['transaction_hour'] = data['TransactionStartTime'].dt.hour\n",
    "data['transaction_day'] = data['TransactionStartTime'].dt.day\n",
    "data['transaction_month'] = data['TransactionStartTime'].dt.month\n",
    "data['transaction_year'] = data['TransactionStartTime'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'Amount', 'Value', 'TransactionStartTime', 'PricingStrategy', 'FraudResult', 'transaction_hour', 'transaction_day', 'transaction_month', 'transaction_year', 'ProviderId_ProviderId_2', 'ProviderId_ProviderId_3', 'ProviderId_ProviderId_4', 'ProviderId_ProviderId_5', 'ProviderId_ProviderId_6', 'ProductId_ProductId_10', 'ProductId_ProductId_11', 'ProductId_ProductId_12', 'ProductId_ProductId_13', 'ProductId_ProductId_14', 'ProductId_ProductId_15', 'ProductId_ProductId_16', 'ProductId_ProductId_19', 'ProductId_ProductId_2', 'ProductId_ProductId_20', 'ProductId_ProductId_21', 'ProductId_ProductId_22', 'ProductId_ProductId_23', 'ProductId_ProductId_24', 'ProductId_ProductId_27', 'ProductId_ProductId_3', 'ProductId_ProductId_4', 'ProductId_ProductId_5', 'ProductId_ProductId_6', 'ProductId_ProductId_7', 'ProductId_ProductId_8', 'ProductId_ProductId_9', 'ProductCategory_data_bundles', 'ProductCategory_financial_services', 'ProductCategory_movies', 'ProductCategory_other', 'ProductCategory_ticket', 'ProductCategory_transport', 'ProductCategory_tv', 'ProductCategory_utility_bill', 'ChannelId_ChannelId_2', 'ChannelId_ChannelId_3', 'ChannelId_ChannelId_5', 'normalized_amount', 'standardized_amount']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded columns: ['ChannelId_ChannelId_2', 'ChannelId_ChannelId_3', 'ChannelId_ChannelId_5']\n",
      "Label encoded column: PricingStrategy\n",
      "Label encoded column: FraudResult\n",
      "Transformed DataFrame:\n",
      "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
      "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
      "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
      "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
      "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
      "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
      "\n",
      "        CustomerId   Amount  Value      TransactionStartTime  PricingStrategy  \\\n",
      "0  CustomerId_4406   1000.0   1000 2018-11-15 02:18:49+00:00                2   \n",
      "1  CustomerId_4406    -20.0     20 2018-11-15 02:19:08+00:00                2   \n",
      "2  CustomerId_4683    500.0    500 2018-11-15 02:44:21+00:00                2   \n",
      "3   CustomerId_988  20000.0  21800 2018-11-15 03:32:55+00:00                2   \n",
      "4   CustomerId_988   -644.0    644 2018-11-15 03:34:21+00:00                2   \n",
      "\n",
      "   FraudResult  ...  ProductCategory_other  ProductCategory_ticket  \\\n",
      "0            0  ...                  False                   False   \n",
      "1            0  ...                  False                   False   \n",
      "2            0  ...                  False                   False   \n",
      "3            0  ...                  False                   False   \n",
      "4            0  ...                  False                   False   \n",
      "\n",
      "   ProductCategory_transport  ProductCategory_tv  \\\n",
      "0                      False               False   \n",
      "1                      False               False   \n",
      "2                      False               False   \n",
      "3                      False               False   \n",
      "4                      False               False   \n",
      "\n",
      "   ProductCategory_utility_bill  normalized_amount  standardized_amount  \\\n",
      "0                         False           0.092004            -0.046371   \n",
      "1                         False           0.091910            -0.054643   \n",
      "2                         False           0.091958            -0.050426   \n",
      "3                          True           0.093750             0.107717   \n",
      "4                         False           0.091853            -0.059704   \n",
      "\n",
      "   ChannelId_ChannelId_2_True  ChannelId_ChannelId_3_True  \\\n",
      "0                       False                        True   \n",
      "1                        True                       False   \n",
      "2                       False                        True   \n",
      "3                       False                        True   \n",
      "4                        True                       False   \n",
      "\n",
      "   ChannelId_ChannelId_5_True  \n",
      "0                       False  \n",
      "1                       False  \n",
      "2                       False  \n",
      "3                       False  \n",
      "4                       False  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# One-Hot Encoding for existing categorical columns\n",
    "one_hot_columns = ['ChannelId_ChannelId_2', 'ChannelId_ChannelId_3', 'ChannelId_ChannelId_5']\n",
    "\n",
    "# Check for missing columns and apply One-Hot Encoding\n",
    "existing_one_hot_columns = [col for col in one_hot_columns if col in data.columns]\n",
    "if existing_one_hot_columns:\n",
    "    data = pd.get_dummies(data, columns=existing_one_hot_columns, drop_first=True)\n",
    "    print(f\"One-hot encoded columns: {existing_one_hot_columns}\")\n",
    "else:\n",
    "    print(f\"No columns found for one-hot encoding from: {one_hot_columns}\")\n",
    "\n",
    "# Label Encoding for PricingStrategy and FraudResult\n",
    "label_encoder = LabelEncoder()\n",
    "label_encode_columns = ['PricingStrategy', 'FraudResult']\n",
    "\n",
    "for column in label_encode_columns:\n",
    "    if column in data.columns:\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "        print(f\"Label encoded column: {column}\")\n",
    "    else:\n",
    "        print(f\"Column {column} not found for label encoding.\")\n",
    "\n",
    "# Check the transformed data\n",
    "print(\"Transformed DataFrame:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Series([], dtype: int64)\n",
      "Missing values after imputation:\n",
      "TransactionId                         0\n",
      "BatchId                               0\n",
      "AccountId                             0\n",
      "SubscriptionId                        0\n",
      "CustomerId                            0\n",
      "Amount                                0\n",
      "Value                                 0\n",
      "TransactionStartTime                  0\n",
      "PricingStrategy                       0\n",
      "FraudResult                           0\n",
      "transaction_hour                      0\n",
      "transaction_day                       0\n",
      "transaction_month                     0\n",
      "transaction_year                      0\n",
      "ProviderId_ProviderId_2               0\n",
      "ProviderId_ProviderId_3               0\n",
      "ProviderId_ProviderId_4               0\n",
      "ProviderId_ProviderId_5               0\n",
      "ProviderId_ProviderId_6               0\n",
      "ProductId_ProductId_10                0\n",
      "ProductId_ProductId_11                0\n",
      "ProductId_ProductId_12                0\n",
      "ProductId_ProductId_13                0\n",
      "ProductId_ProductId_14                0\n",
      "ProductId_ProductId_15                0\n",
      "ProductId_ProductId_16                0\n",
      "ProductId_ProductId_19                0\n",
      "ProductId_ProductId_2                 0\n",
      "ProductId_ProductId_20                0\n",
      "ProductId_ProductId_21                0\n",
      "ProductId_ProductId_22                0\n",
      "ProductId_ProductId_23                0\n",
      "ProductId_ProductId_24                0\n",
      "ProductId_ProductId_27                0\n",
      "ProductId_ProductId_3                 0\n",
      "ProductId_ProductId_4                 0\n",
      "ProductId_ProductId_5                 0\n",
      "ProductId_ProductId_6                 0\n",
      "ProductId_ProductId_7                 0\n",
      "ProductId_ProductId_8                 0\n",
      "ProductId_ProductId_9                 0\n",
      "ProductCategory_data_bundles          0\n",
      "ProductCategory_financial_services    0\n",
      "ProductCategory_movies                0\n",
      "ProductCategory_other                 0\n",
      "ProductCategory_ticket                0\n",
      "ProductCategory_transport             0\n",
      "ProductCategory_tv                    0\n",
      "ProductCategory_utility_bill          0\n",
      "normalized_amount                     0\n",
      "standardized_amount                   0\n",
      "ChannelId_ChannelId_2_True            0\n",
      "ChannelId_ChannelId_3_True            0\n",
      "ChannelId_ChannelId_5_True            0\n",
      "dtype: int64\n",
      "Data after normalization:\n",
      "     Amount     Value\n",
      "0  0.092004  0.000101\n",
      "1  0.091910  0.000002\n",
      "2  0.091958  0.000050\n",
      "3  0.093750  0.002206\n",
      "4  0.091853  0.000065\n",
      "Data after standardization:\n",
      "     Amount     Value\n",
      "0 -0.046371 -0.072291\n",
      "1 -0.054643 -0.080251\n",
      "2 -0.050426 -0.076352\n",
      "3  0.107717  0.096648\n",
      "4 -0.059704 -0.075183\n",
      "Final DataFrame:\n",
      "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
      "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
      "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
      "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
      "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
      "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
      "\n",
      "        CustomerId    Amount     Value      TransactionStartTime  \\\n",
      "0  CustomerId_4406 -0.046371 -0.072291 2018-11-15 02:18:49+00:00   \n",
      "1  CustomerId_4406 -0.054643 -0.080251 2018-11-15 02:19:08+00:00   \n",
      "2  CustomerId_4683 -0.050426 -0.076352 2018-11-15 02:44:21+00:00   \n",
      "3   CustomerId_988  0.107717  0.096648 2018-11-15 03:32:55+00:00   \n",
      "4   CustomerId_988 -0.059704 -0.075183 2018-11-15 03:34:21+00:00   \n",
      "\n",
      "   PricingStrategy  FraudResult  ...  ProductCategory_other  \\\n",
      "0                2            0  ...                  False   \n",
      "1                2            0  ...                  False   \n",
      "2                2            0  ...                  False   \n",
      "3                2            0  ...                  False   \n",
      "4                2            0  ...                  False   \n",
      "\n",
      "   ProductCategory_ticket  ProductCategory_transport  ProductCategory_tv  \\\n",
      "0                   False                      False               False   \n",
      "1                   False                      False               False   \n",
      "2                   False                      False               False   \n",
      "3                   False                      False               False   \n",
      "4                   False                      False               False   \n",
      "\n",
      "   ProductCategory_utility_bill  normalized_amount  standardized_amount  \\\n",
      "0                         False           0.092004            -0.046371   \n",
      "1                         False           0.091910            -0.054643   \n",
      "2                         False           0.091958            -0.050426   \n",
      "3                          True           0.093750             0.107717   \n",
      "4                         False           0.091853            -0.059704   \n",
      "\n",
      "   ChannelId_ChannelId_2_True  ChannelId_ChannelId_3_True  \\\n",
      "0                       False                        True   \n",
      "1                        True                       False   \n",
      "2                       False                        True   \n",
      "3                       False                        True   \n",
      "4                        True                       False   \n",
      "\n",
      "   ChannelId_ChannelId_5_True  \n",
      "0                       False  \n",
      "1                       False  \n",
      "2                       False  \n",
      "3                       False  \n",
      "4                       False  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Impute missing values\n",
    "# Choose imputation strategy\n",
    "imputation_strategy = 'mean'  \n",
    "\n",
    "# Identify numerical columns for imputation\n",
    "numerical_columns = ['Amount', 'Value']  # Numerical columns\n",
    "\n",
    "# Create imputer for numerical columns\n",
    "imputer = SimpleImputer(strategy=imputation_strategy)\n",
    "\n",
    "# Apply imputation\n",
    "data[numerical_columns] = imputer.fit_transform(data[numerical_columns])\n",
    "print(\"Missing values after imputation:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Normalize and Standardize Numerical Features\n",
    "# Normalize selected numerical columns\n",
    "normalizer = MinMaxScaler()\n",
    "data[numerical_columns] = normalizer.fit_transform(data[numerical_columns])\n",
    "print(\"Data after normalization:\")\n",
    "print(data[numerical_columns].head())\n",
    "\n",
    "# Standardize selected numerical columns\n",
    "standardizer = StandardScaler()\n",
    "data[numerical_columns] = standardizer.fit_transform(data[numerical_columns])\n",
    "print(\"Data after standardization:\")\n",
    "print(data[numerical_columns].head())\n",
    "\n",
    "# Final DataFrame\n",
    "print(\"Final DataFrame:\")\n",
    "print(data.head())\n",
    "\n",
    "# save the processed DataFrame\n",
    "data.to_csv('processed_bati_bank_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CustomerId   recency  frequency  monetary  RFMS_score\n",
      "0     CustomerId_1  0.922222   0.000000  0.615480    0.491985\n",
      "1    CustomerId_10  0.922222   0.000000  0.615480    0.491985\n",
      "2  CustomerId_1001  0.988889   0.000978  0.615495    0.519046\n",
      "3  CustomerId_1002  0.288889   0.002445  0.615234    0.239580\n",
      "4  CustomerId_1003  0.133333   0.001222  0.615463    0.176915\n"
     ]
    }
   ],
   "source": [
    "# Ensure TransactionStartTime is in datetime format\n",
    "data['TransactionStartTime'] = pd.to_datetime(data['TransactionStartTime'])\n",
    "\n",
    "# Convert TransactionStartTime to timezone-naive\n",
    "data['TransactionStartTime'] = data['TransactionStartTime'].dt.tz_localize(None)\n",
    "\n",
    "# Calculate Recency, Frequency, Monetary Score (RFMS)\n",
    "now = datetime.now()  \n",
    "\n",
    "rfms = data.groupby('CustomerId').agg(\n",
    "    recency=('TransactionStartTime', lambda x: (now - x.max()).days),  \n",
    "    frequency=('TransactionId', 'count'),  \n",
    "    monetary=('Amount', 'sum')  \n",
    ").reset_index()\n",
    "\n",
    "# Normalize the metrics (optional, for better boundary establishment)\n",
    "rfms['recency'] = (rfms['recency'] - rfms['recency'].min()) / (rfms['recency'].max() - rfms['recency'].min())\n",
    "rfms['frequency'] = (rfms['frequency'] - rfms['frequency'].min()) / (rfms['frequency'].max() - rfms['frequency'].min())\n",
    "rfms['monetary'] = (rfms['monetary'] - rfms['monetary'].min()) / (rfms['monetary'].max() - rfms['monetary'].min())\n",
    "\n",
    "# Create RFMS score (you can adjust the weights)\n",
    "rfms['RFMS_score'] = 0.4 * rfms['recency'] + 0.4 * rfms['frequency'] + 0.2 * rfms['monetary']\n",
    "\n",
    "# View RFMS DataFrame\n",
    "print(rfms.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CustomerId  RFMS_score label\n",
      "0     CustomerId_1    0.491985  good\n",
      "1    CustomerId_10    0.491985  good\n",
      "2  CustomerId_1001    0.519046  good\n",
      "3  CustomerId_1002    0.239580  good\n",
      "4  CustomerId_1003    0.176915   bad\n"
     ]
    }
   ],
   "source": [
    "# Establish a threshold for classification\n",
    "threshold = rfms['RFMS_score'].median()  # You can also set a custom threshold\n",
    "\n",
    "# Classify users\n",
    "rfms['label'] = np.where(rfms['RFMS_score'] >= threshold, 'good', 'bad')\n",
    "\n",
    "# View labeled RFMS DataFrame\n",
    "print(rfms[['CustomerId', 'RFMS_score', 'label']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RFMS_score  good  bad  good_dist  bad_dist  woe  IV\n",
      "0    0.176915   NaN  1.0        NaN       1.0  0.0 NaN\n",
      "1    0.239580   1.0  NaN       0.25       NaN  0.0 NaN\n",
      "2    0.491985   2.0  NaN       0.50       NaN  0.0 NaN\n",
      "3    0.519046   1.0  NaN       0.25       NaN  0.0 NaN\n",
      "Overall IV value: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample DataFrame with CustomerId, RFMS_score, and label\n",
    "data = {\n",
    "    'CustomerId': ['CustomerId_1', 'CustomerId_10', 'CustomerId_1001', 'CustomerId_1002', 'CustomerId_1003'],\n",
    "    'RFMS_score': [0.491985, 0.491985, 0.519046, 0.239580, 0.176915],\n",
    "    'label': ['good', 'good', 'good', 'good', 'bad']\n",
    "}\n",
    "\n",
    "rfms = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate WoE and IV\n",
    "def calculate_woe_iv(data, target, feature):\n",
    "    # Total counts of 'good' and 'bad'\n",
    "    total_good = data[target].value_counts().get('good', 0)\n",
    "    total_bad = data[target].value_counts().get('bad', 0)\n",
    "\n",
    "    # Create a DataFrame for WoE calculation\n",
    "    woe_df = data[[feature, target]].copy()\n",
    "    woe_df['good'] = np.where(woe_df[target] == 'good', 1, 0)\n",
    "    woe_df['bad'] = np.where(woe_df[target] == 'bad', 1, 0)\n",
    "\n",
    "    # Group by feature and calculate sums\n",
    "    woe_summary = woe_df.groupby(feature).agg(\n",
    "        good=('good', 'sum'),\n",
    "        bad=('bad', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    woe_summary['good'] = woe_summary['good'].replace(0, np.nan)\n",
    "    woe_summary['bad'] = woe_summary['bad'].replace(0, np.nan)\n",
    "\n",
    "    woe_summary['good_dist'] = woe_summary['good'] / total_good if total_good > 0 else 0\n",
    "    woe_summary['bad_dist'] = woe_summary['bad'] / total_bad if total_bad > 0 else 0\n",
    "    \n",
    "    woe_summary['woe'] = np.log(woe_summary['good_dist'] / woe_summary['bad_dist']).replace({np.inf: np.nan, -np.inf: np.nan}).fillna(0)\n",
    "\n",
    "    # Calculate IV\n",
    "    woe_summary['IV'] = (woe_summary['good_dist'] - woe_summary['bad_dist']) * woe_summary['woe']\n",
    "\n",
    "    iv_value = woe_summary['IV'].sum()\n",
    "    \n",
    "    return woe_summary, iv_value\n",
    "\n",
    "# Perform WoE and IV calculation\n",
    "woe_result, iv_value = calculate_woe_iv(rfms, 'label', 'RFMS_score')\n",
    "\n",
    "# Display WoE results\n",
    "print(woe_result)\n",
    "print(f\"Overall IV value: {iv_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
